{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337a1de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "#import data\n",
    "data = pd.read_csv(\"agaricus-lepiota.data\",header=None,na_values=[\"?\",None])\n",
    "\n",
    "uniqueValues = {}\n",
    "#this is a file that has all the column names in a csv format and also has an extra \"class\" at the first column\n",
    "featureCol = pd.read_csv(\"agaricus-lepiota.csv\")\n",
    "\n",
    "\n",
    "data.columns = list(featureCol.columns)\n",
    "data.dropna(inplace = True)\n",
    "for feature in data.columns:\n",
    "    uniqueValues[feature] = data[feature].unique()\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature, children = [], type=\"split\"):\n",
    "        self.feature = feature\n",
    "        if isinstance(children, list) == False:\n",
    "            self.children = [children]\n",
    "        else:\n",
    "            self.children = children;\n",
    "        self.type = type\n",
    "        \n",
    "        \n",
    "def singleLog(num,den):\n",
    "    if (den == 0 or num == 0):\n",
    "        return 0\n",
    "    elif (den == num):\n",
    "        return 0\n",
    "    return -(num/den)*np.log2(num/den)\n",
    "\n",
    "def FeatureEntropy(data,feature):\n",
    "    uniqueValues = data[feature].unique()\n",
    "    big_total = len(data.index)\n",
    "    entropy = 0\n",
    "    for value in uniqueValues:\n",
    "        value_in_data = data[data[feature]==value]\n",
    "        total = len(value_in_data.index)\n",
    "        num_p = len(value_in_data[value_in_data[\"class\"] == \"p\"])\n",
    "        num_e = len(value_in_data[value_in_data[\"class\"] == \"e\"])\n",
    "        partialEntropy = singleLog(num_p,total) + singleLog(num_e,total)\n",
    "        entropy += (total/big_total)*partialEntropy\n",
    "    return entropy\n",
    "\n",
    "def trainGreedyDecisionTree(data, current_depth = 0, stopping_depth = float('inf')):\n",
    "    columns = list(data.columns)\n",
    "    total_rows = len(data.index)\n",
    "    num_p = len(data[data[\"class\"] == \"p\"])\n",
    "    num_e = len(data[data[\"class\"] == \"e\"])\n",
    "    current_entropy = singleLog(num_p,total_rows)+singleLog(num_e,total_rows)\n",
    "    array_of_ig = {}\n",
    "    if stopping_depth == 1:\n",
    "        stopping_depth = 2\n",
    "    if current_depth >= stopping_depth-1:\n",
    "        if num_p > num_e:\n",
    "            return Node(\"p\", [], \"output\")\n",
    "        else:\n",
    "            return Node(\"e\", [], \"output\")\n",
    "    #if dataset is empty then return\n",
    "    if len(data.index) == 0:\n",
    "        return []\n",
    "    class_label = data[\"class\"].unique()\n",
    "    \n",
    "    #if all class labels are the same then exit recursion and output \n",
    "    if len(class_label) == 1:\n",
    "        return Node(class_label[0],[],\"output\")\n",
    "\n",
    "\n",
    "    #if all inputs are the same then exit recursion and output\n",
    "    if (data.duplicated().sum() == len(data.index)):\n",
    "        if num_p > num_e:\n",
    "            return Node(\"p\", [], \"output\")\n",
    "        else:\n",
    "            return Node(\"e\", [], \"output\")\n",
    "    \n",
    "    #calculate largest information gain for each feature\n",
    "    for feature in columns:\n",
    "        if feature == \"class\":\n",
    "            pass\n",
    "        else:\n",
    "            array_of_ig[feature] = current_entropy - FeatureEntropy(data,feature)\n",
    "    #TODO: change to choosing feature by IG = H(Y) - H(X)\n",
    "    largest_IG_feature = max(array_of_ig, key=array_of_ig.get)\n",
    "    #if largest IG feature only has 1 unique feature remaining then it must exit\n",
    "    #class label will be whatever has majority \n",
    "    \n",
    "\n",
    "    #split the dataset by the features different options \n",
    "    child_nodes = []\n",
    "    #recursively call function and split dataset by the feature options\n",
    "    largest_features_unique = uniqueValues[largest_IG_feature]\n",
    "    largest_features_unique_in_dataset = data[largest_IG_feature].unique()\n",
    "    for value in largest_features_unique:\n",
    "        #case if a unique value does not exist in the dataset, assume an output of p\n",
    "        if value in largest_features_unique_in_dataset:\n",
    "            split_dataset = data[data[largest_IG_feature] == value].drop(largest_IG_feature,axis=1)\n",
    "            child_nodes.append(Node(value,trainGreedyDecisionTree(split_dataset,current_depth+1,stopping_depth)))\n",
    "        else:\n",
    "            child_nodes.append(Node(value, Node(\"p\",[],\"output\")))\n",
    "        \n",
    "    root = Node(largest_IG_feature, child_nodes)\n",
    "    return root\n",
    "\n",
    "def testWithUsedSamples(graph,data):\n",
    "    num_incorrect = 0\n",
    "    current_node = graph\n",
    "    for ind in data.index:\n",
    "        while current_node.type != \"output\":\n",
    "            feature = current_node.feature\n",
    "            next_feature = data[feature][ind]\n",
    "            for j in current_node.children:\n",
    "                if j.feature == next_feature:\n",
    "                    current_node = j\n",
    "            if len(current_node.children) == 1:\n",
    "                current_node = current_node.children[0]\n",
    "        label = current_node.feature\n",
    "        current_node = graph\n",
    "        if label != data[\"class\"][ind]:\n",
    "            num_incorrect += 1\n",
    "    return num_incorrect\n",
    "\n",
    "def drawGraph(graph, depth):\n",
    "    if (len(graph.feature) != 1):\n",
    "        print(\"Depth: \"+ str(depth//2+1))\n",
    "    print(\"feature: \" + graph.feature)\n",
    "\n",
    "    for child in graph.children:\n",
    "        if len(child.children) == 1 and child.children[0].type == \"output\":\n",
    "            print(\"child: \"+child.feature)\n",
    "            print(\"output: \"+ child.children[0].feature)\n",
    "        else:\n",
    "            print(\"child: \"+child.feature)\n",
    "    print()\n",
    "    for child in graph.children:\n",
    "        if len(child.children) != 1 or (len(child.children) == 1 and child.children[0].type != \"output\"):\n",
    "            drawGraph(child, (depth+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97311724-7b29-4a82-ba4a-605aeed8aa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1\n",
      "feature: odor\n",
      "child: p\n",
      "output: p\n",
      "child: a\n",
      "output: e\n",
      "child: l\n",
      "output: e\n",
      "child: n\n",
      "output: e\n",
      "child: f\n",
      "output: p\n",
      "child: c\n",
      "output: p\n",
      "child: m\n",
      "output: p\n",
      "\n",
      "----------------------------------\n",
      "Depth: 1\n",
      "feature: odor\n",
      "child: p\n",
      "output: p\n",
      "child: a\n",
      "output: e\n",
      "child: l\n",
      "output: e\n",
      "child: n\n",
      "child: f\n",
      "output: p\n",
      "child: c\n",
      "output: p\n",
      "child: m\n",
      "output: p\n",
      "\n",
      "feature: n\n",
      "child: spore-print-color\n",
      "\n",
      "Depth: 2\n",
      "feature: spore-print-color\n",
      "child: k\n",
      "output: e\n",
      "child: n\n",
      "output: e\n",
      "child: u\n",
      "output: p\n",
      "child: h\n",
      "output: p\n",
      "child: r\n",
      "output: p\n",
      "child: w\n",
      "output: e\n",
      "\n",
      "----------------------------------\n",
      "Depth: 1\n",
      "feature: odor\n",
      "child: p\n",
      "output: p\n",
      "child: a\n",
      "output: e\n",
      "child: l\n",
      "output: e\n",
      "child: n\n",
      "child: f\n",
      "output: p\n",
      "child: c\n",
      "output: p\n",
      "child: m\n",
      "output: p\n",
      "\n",
      "feature: n\n",
      "child: spore-print-color\n",
      "\n",
      "Depth: 2\n",
      "feature: spore-print-color\n",
      "child: k\n",
      "output: e\n",
      "child: n\n",
      "output: e\n",
      "child: u\n",
      "output: p\n",
      "child: h\n",
      "output: p\n",
      "child: r\n",
      "output: p\n",
      "child: w\n",
      "\n",
      "feature: w\n",
      "child: cap-color\n",
      "\n",
      "Depth: 3\n",
      "feature: cap-color\n",
      "child: n\n",
      "output: e\n",
      "child: y\n",
      "output: p\n",
      "child: w\n",
      "output: p\n",
      "child: g\n",
      "output: e\n",
      "child: e\n",
      "output: p\n",
      "child: p\n",
      "output: e\n",
      "child: b\n",
      "output: p\n",
      "child: c\n",
      "output: e\n",
      "\n",
      "----------------------------------\n",
      "Depth: 1\n",
      "feature: odor\n",
      "child: p\n",
      "output: p\n",
      "child: a\n",
      "output: e\n",
      "child: l\n",
      "output: e\n",
      "child: n\n",
      "child: f\n",
      "output: p\n",
      "child: c\n",
      "output: p\n",
      "child: m\n",
      "output: p\n",
      "\n",
      "feature: n\n",
      "child: spore-print-color\n",
      "\n",
      "Depth: 2\n",
      "feature: spore-print-color\n",
      "child: k\n",
      "output: e\n",
      "child: n\n",
      "output: e\n",
      "child: u\n",
      "output: p\n",
      "child: h\n",
      "output: p\n",
      "child: r\n",
      "output: p\n",
      "child: w\n",
      "\n",
      "feature: w\n",
      "child: cap-color\n",
      "\n",
      "Depth: 3\n",
      "feature: cap-color\n",
      "child: n\n",
      "output: e\n",
      "child: y\n",
      "output: p\n",
      "child: w\n",
      "output: p\n",
      "child: g\n",
      "output: e\n",
      "child: e\n",
      "output: p\n",
      "child: p\n",
      "output: e\n",
      "child: b\n",
      "output: p\n",
      "child: c\n",
      "output: e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print( testWithUsedSamples(trainGreedyDecisionTree(data), data.sample(100))/1000)\n",
    "depth = 1\n",
    "stopping_depth = depth*2-1\n",
    "drawGraph(trainGreedyDecisionTree(data,0,stopping_depth),1)\n",
    "print(\"----------------------------------\")\n",
    "depth = 2\n",
    "stopping_depth = depth*2-1\n",
    "drawGraph(trainGreedyDecisionTree(data,0,stopping_depth),1)\n",
    "print(\"----------------------------------\")\n",
    "depth = 3\n",
    "stopping_depth = depth*2-1\n",
    "drawGraph(trainGreedyDecisionTree(data,0,stopping_depth),1)\n",
    "print(\"----------------------------------\")\n",
    "depth = 4\n",
    "stopping_depth = depth*2-1\n",
    "drawGraph(trainGreedyDecisionTree(data,0,stopping_depth),1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d598455-a7c7-4489-b698-5214b489e930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#Q2C\n",
    "print(testWithUsedSamples(trainGreedyDecisionTree(data,0,stopping_depth), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c45e74f-5272-4732-89a5-c1082b516088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.017721518987341773, 2: 0.005063291139240506, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0, 10: 0, 11: 0, 12: 0, 13: 0, 14: 0, 15: 0, 16: 0, 17: 0, 18: 0, 19: 0, 20: 0, 21: 0, 22: 0}\n",
      "smallest validation error: 0\n",
      "training error: 0.0\n",
      "best hyperparameter (height of tree): 3\n",
      "test error: 0.0\n",
      "variance: 0.0\n",
      "bias: 0.0\n",
      "noise: 0\n",
      "model error: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Q2D\n",
    "#step 1 shuffle data\n",
    "shuffled = data.sample(frac=1)\n",
    "#step 2 split data\n",
    "percentage_training_to_test = 0.7\n",
    "training, test = np.split(shuffled, [int(percentage_training_to_test*len(data))])\n",
    "#step 3 split training into training and validation\n",
    "shuffled = training.sample(frac=1)\n",
    "percentage_training_to_validation = 0.9\n",
    "training, validation = np.split(shuffled, [int(percentage_training_to_validation*len(shuffled))])\n",
    "\n",
    "\n",
    "#find best hyperparameter values\n",
    "hyperparameter = {}\n",
    "for j in range(1,len(training.columns)):\n",
    "    stopping_depth = j\n",
    "\n",
    "    model = trainGreedyDecisionTree(training, 0, stopping_depth*2-1)\n",
    "    x = testWithUsedSamples(model,validation)\n",
    "    if (x == 0 or len(validation)==0):\n",
    "        hyperparameter[stopping_depth] = 0\n",
    "    else:\n",
    "        hyperparameter[stopping_depth] = x/(len(validation))*1.0\n",
    "\n",
    "#choose the hyper parameter that gives the lowest validation error\n",
    "best_validation = min(hyperparameter, key=hyperparameter.get)\n",
    "\n",
    "\n",
    "#step 3 train model\n",
    "model = trainGreedyDecisionTree(training, 0 , best_validation*2-1)\n",
    "test_error = testWithUsedSamples(model,test)/(len(test))\n",
    "train_error = testWithUsedSamples(model,training)/len(training)\n",
    "best_error = 0 #lowest possible error\n",
    "print(hyperparameter)\n",
    "print(\"smallest validation error: \"+str(hyperparameter[best_validation]))\n",
    "print(\"training error: \"+str(train_error))\n",
    "print(\"best hyperparameter (height of tree): \"+str(best_validation))\n",
    "print(\"test error: \"+str(test_error))\n",
    "print(\"variance: \"+str(test_error-train_error))\n",
    "print(\"bias: \"+str(train_error-best_error))\n",
    "print(\"noise: \"+str(best_error))\n",
    "print(\"model error: \"+str(test_error-train_error+train_error-best_error+best_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f61a611-1515-4ba8-9b81-83db877a86e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0efd1c8-41db-462e-91b0-7a0b1ae59b97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
